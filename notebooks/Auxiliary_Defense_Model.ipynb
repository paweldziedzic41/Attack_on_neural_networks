{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM/Ru4Q2N9WKELkbNe/FVe7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import to_categorical\n","from keras.models import Sequential, load_model\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","from keras.optimizers import Adam\n","from keras.callbacks import LearningRateScheduler\n","from keras.callbacks import EarlyStopping\n","import tensorflow as tf\n","import time"],"metadata":{"id":"QGALRkYqAcik","executionInfo":{"status":"ok","timestamp":1738488665835,"user_tz":-60,"elapsed":5194,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Wczytaj:\n","# - train.csv\n","# - model.h5"],"metadata":{"id":"my3giM7D5Q09","executionInfo":{"status":"ok","timestamp":1738488665835,"user_tz":-60,"elapsed":3,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.models.load_model('model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5opsdxWRAhic","executionInfo":{"status":"ok","timestamp":1738488668698,"user_tz":-60,"elapsed":2865,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}},"outputId":"52218a1e-3f89-46e4-e52b-7bc52955719b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]}]},{"cell_type":"code","source":["def pgd_attack(model, images, labels, epsilon, c, num_iterations, norm_type='Linf', threshold=None):\n","    \"\"\"\n","    Przeprowadza atak PGD z kontrolą normy perturbacji i możliwością wcześniejszego zakończenia.\n","\n","    Parametry:\n","    - model: Model Keras lub TensorFlow\n","    - images: Obrazy wejściowe (batch)\n","    - labels: Etykiety one-hot dla obrazów\n","    - epsilon: Maksymalna wielkość perturbacji\n","    - alpha: Krok każdej iteracji\n","    - num_iterations: Maksymalna liczba iteracji\n","    - norm_type: Typ normy ('l0', 'l1', 'l2', 'linf')\n","    - threshold: Próg zmiany perturbacji dla wcześniejszego zakończenia (opcjonalny)\n","\n","    Zwraca:\n","    - Adwersarialne obrazy\n","    \"\"\"\n","    # Inicjalizujemy perturbacje jako kopię obrazów wejściowych\n","    perturbed_images = tf.identity(images)\n","\n","    for i in range(num_iterations):\n","        with tf.GradientTape() as tape:\n","            tape.watch(perturbed_images)\n","            predictions = model(perturbed_images)\n","            loss = tf.keras.losses.categorical_crossentropy(labels, predictions)\n","\n","        # Obliczamy gradient\n","        gradient = tape.gradient(loss, perturbed_images)\n","\n","        # Generowanie perturbacji na podstawie wybranej normy\n","        if norm_type == 'Linf':\n","            perturbation = c * tf.sign(gradient)\n","        elif norm_type == 'L2':\n","            # Ręczne obliczenie normy L2\n","            norm = tf.sqrt(tf.reduce_sum(tf.square(gradient), axis=(1, 2, 3), keepdims=True))\n","            perturbation = c * gradient / (norm + 1e-10)\n","        else:\n","            raise ValueError(\"Nieobsługiwana norma. Użyj 'l0', 'l1', 'l2' lub 'linf'.\")\n","\n","        # Aktualizacja obrazów adwersarialnych\n","        new_perturbed_images = perturbed_images + perturbation\n","        new_perturbed_images = tf.clip_by_value(new_perturbed_images, images - epsilon, images + epsilon)  # projekcja\n","        new_perturbed_images = tf.clip_by_value(new_perturbed_images, 0, 1)  # ograniczenie do zakresu [0,1]\n","\n","        # Sprawdzenie progu zmiany perturbacji\n","        if threshold is not None:\n","            delta = tf.reduce_max(tf.abs(new_perturbed_images - perturbed_images))\n","            if delta < threshold:\n","                print(f\"Zatrzymanie po {i + 1} iteracjach (zmiana < {threshold})\")\n","                break\n","\n","        perturbed_images = new_perturbed_images\n","\n","    return perturbed_images\n"],"metadata":{"id":"96Vps_8D5uO6","executionInfo":{"status":"ok","timestamp":1738488668698,"user_tz":-60,"elapsed":3,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["datagen = ImageDataGenerator(\n","            featurewise_center=False,  # set input mean to 0 over the dataset\n","            samplewise_center=False,  # set each sample mean to 0\n","            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","            samplewise_std_normalization=False,  # divide each input by its std\n","            zca_whitening=False,  # apply ZCA whitening\n","            rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","            zoom_range = 0.1, # Randomly zoom image\n","            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","            horizontal_flip=False,  # randomly flip images\n","            vertical_flip=False)  # randomly flip images"],"metadata":{"id":"tcV078w0CK9O","executionInfo":{"status":"ok","timestamp":1738488668698,"user_tz":-60,"elapsed":3,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('train.csv')\n","\n","X = data.iloc[:,1:]\n","Y = data.iloc[:,0]\n","\n","X_reshaped = X.values.reshape(-1, 28, 28, 1)"],"metadata":{"id":"rlJEi8cgCMhF","executionInfo":{"status":"ok","timestamp":1738488670891,"user_tz":-60,"elapsed":2195,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["x_train , x_test , y_train , y_test = train_test_split(X_reshaped, Y, test_size=0.1)\n","\n","x_train = x_train.astype(\"float32\")/255\n","x_test = x_test.astype(\"float32\")/255\n","\n","datagen.fit(x_train)"],"metadata":{"id":"QjEP--ZlCQCr","executionInfo":{"status":"ok","timestamp":1738488671371,"user_tz":-60,"elapsed":482,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["y_train = to_categorical(y_train, num_classes=10)\n","y_test = to_categorical(y_test, num_classes=10)"],"metadata":{"id":"jAMB5VJcCSHz","executionInfo":{"status":"ok","timestamp":1738488671371,"user_tz":-60,"elapsed":2,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Generowanie danych adwersarialnych dla zbioru treningowego\n","batch_size_train = 63\n","x_train_adv = []\n","for i in range(0, len(x_train), batch_size_train):\n","    batch_images = x_train[i:i+batch_size_train]\n","    batch_labels = y_train[i:i+batch_size_train]\n","    print(f\"Generuję dane adwersarialne dla treningu: batch {i} - {i+batch_size_train}\")\n","    adv_images = pgd_attack(model, batch_images, batch_labels, epsilon=0.01, c=0.3, num_iterations=50, norm_type=\"L2\")\n","    x_train_adv.append(adv_images)\n","\n","x_train_adv = np.concatenate(x_train_adv, axis=0)\n","\n","# Zapis danych adwersarialnych dla zbioru treningowego\n","np.savez_compressed(\"adversarial_train_images.npz\", X_train_adv=x_train_adv)\n","print(\"Dane adwersarialne dla treningu zostały zapisane jako 'adversarial_train_images.npz'.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"b5VmtbigCTqp","executionInfo":{"status":"error","timestamp":1738489074997,"user_tz":-60,"elapsed":403628,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}},"outputId":"b62243fc-952f-4648-c769-044c6960568d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Generuję dane adwersarialne dla treningu: batch 0 - 63\n","Generuję dane adwersarialne dla treningu: batch 63 - 126\n","Generuję dane adwersarialne dla treningu: batch 126 - 189\n","Generuję dane adwersarialne dla treningu: batch 189 - 252\n","Generuję dane adwersarialne dla treningu: batch 252 - 315\n","Generuję dane adwersarialne dla treningu: batch 315 - 378\n","Generuję dane adwersarialne dla treningu: batch 378 - 441\n","Generuję dane adwersarialne dla treningu: batch 441 - 504\n","Generuję dane adwersarialne dla treningu: batch 504 - 567\n","Generuję dane adwersarialne dla treningu: batch 567 - 630\n","Generuję dane adwersarialne dla treningu: batch 630 - 693\n","Generuję dane adwersarialne dla treningu: batch 693 - 756\n","Generuję dane adwersarialne dla treningu: batch 756 - 819\n","Generuję dane adwersarialne dla treningu: batch 819 - 882\n","Generuję dane adwersarialne dla treningu: batch 882 - 945\n","Generuję dane adwersarialne dla treningu: batch 945 - 1008\n","Generuję dane adwersarialne dla treningu: batch 1008 - 1071\n","Generuję dane adwersarialne dla treningu: batch 1071 - 1134\n","Generuję dane adwersarialne dla treningu: batch 1134 - 1197\n","Generuję dane adwersarialne dla treningu: batch 1197 - 1260\n","Generuję dane adwersarialne dla treningu: batch 1260 - 1323\n","Generuję dane adwersarialne dla treningu: batch 1323 - 1386\n","Generuję dane adwersarialne dla treningu: batch 1386 - 1449\n","Generuję dane adwersarialne dla treningu: batch 1449 - 1512\n","Generuję dane adwersarialne dla treningu: batch 1512 - 1575\n","Generuję dane adwersarialne dla treningu: batch 1575 - 1638\n","Generuję dane adwersarialne dla treningu: batch 1638 - 1701\n","Generuję dane adwersarialne dla treningu: batch 1701 - 1764\n","Generuję dane adwersarialne dla treningu: batch 1764 - 1827\n","Generuję dane adwersarialne dla treningu: batch 1827 - 1890\n","Generuję dane adwersarialne dla treningu: batch 1890 - 1953\n","Generuję dane adwersarialne dla treningu: batch 1953 - 2016\n","Generuję dane adwersarialne dla treningu: batch 2016 - 2079\n","Generuję dane adwersarialne dla treningu: batch 2079 - 2142\n","Generuję dane adwersarialne dla treningu: batch 2142 - 2205\n","Generuję dane adwersarialne dla treningu: batch 2205 - 2268\n","Generuję dane adwersarialne dla treningu: batch 2268 - 2331\n","Generuję dane adwersarialne dla treningu: batch 2331 - 2394\n","Generuję dane adwersarialne dla treningu: batch 2394 - 2457\n","Generuję dane adwersarialne dla treningu: batch 2457 - 2520\n","Generuję dane adwersarialne dla treningu: batch 2520 - 2583\n","Generuję dane adwersarialne dla treningu: batch 2583 - 2646\n","Generuję dane adwersarialne dla treningu: batch 2646 - 2709\n","Generuję dane adwersarialne dla treningu: batch 2709 - 2772\n","Generuję dane adwersarialne dla treningu: batch 2772 - 2835\n","Generuję dane adwersarialne dla treningu: batch 2835 - 2898\n","Generuję dane adwersarialne dla treningu: batch 2898 - 2961\n","Generuję dane adwersarialne dla treningu: batch 2961 - 3024\n","Generuję dane adwersarialne dla treningu: batch 3024 - 3087\n","Generuję dane adwersarialne dla treningu: batch 3087 - 3150\n","Generuję dane adwersarialne dla treningu: batch 3150 - 3213\n","Generuję dane adwersarialne dla treningu: batch 3213 - 3276\n","Generuję dane adwersarialne dla treningu: batch 3276 - 3339\n","Generuję dane adwersarialne dla treningu: batch 3339 - 3402\n","Generuję dane adwersarialne dla treningu: batch 3402 - 3465\n","Generuję dane adwersarialne dla treningu: batch 3465 - 3528\n","Generuję dane adwersarialne dla treningu: batch 3528 - 3591\n","Generuję dane adwersarialne dla treningu: batch 3591 - 3654\n","Generuję dane adwersarialne dla treningu: batch 3654 - 3717\n","Generuję dane adwersarialne dla treningu: batch 3717 - 3780\n","Generuję dane adwersarialne dla treningu: batch 3780 - 3843\n","Generuję dane adwersarialne dla treningu: batch 3843 - 3906\n","Generuję dane adwersarialne dla treningu: batch 3906 - 3969\n","Generuję dane adwersarialne dla treningu: batch 3969 - 4032\n","Generuję dane adwersarialne dla treningu: batch 4032 - 4095\n","Generuję dane adwersarialne dla treningu: batch 4095 - 4158\n","Generuję dane adwersarialne dla treningu: batch 4158 - 4221\n","Generuję dane adwersarialne dla treningu: batch 4221 - 4284\n","Generuję dane adwersarialne dla treningu: batch 4284 - 4347\n","Generuję dane adwersarialne dla treningu: batch 4347 - 4410\n","Generuję dane adwersarialne dla treningu: batch 4410 - 4473\n","Generuję dane adwersarialne dla treningu: batch 4473 - 4536\n","Generuję dane adwersarialne dla treningu: batch 4536 - 4599\n","Generuję dane adwersarialne dla treningu: batch 4599 - 4662\n","Generuję dane adwersarialne dla treningu: batch 4662 - 4725\n","Generuję dane adwersarialne dla treningu: batch 4725 - 4788\n","Generuję dane adwersarialne dla treningu: batch 4788 - 4851\n","Generuję dane adwersarialne dla treningu: batch 4851 - 4914\n","Generuję dane adwersarialne dla treningu: batch 4914 - 4977\n","Generuję dane adwersarialne dla treningu: batch 4977 - 5040\n","Generuję dane adwersarialne dla treningu: batch 5040 - 5103\n","Generuję dane adwersarialne dla treningu: batch 5103 - 5166\n","Generuję dane adwersarialne dla treningu: batch 5166 - 5229\n","Generuję dane adwersarialne dla treningu: batch 5229 - 5292\n","Generuję dane adwersarialne dla treningu: batch 5292 - 5355\n","Generuję dane adwersarialne dla treningu: batch 5355 - 5418\n","Generuję dane adwersarialne dla treningu: batch 5418 - 5481\n","Generuję dane adwersarialne dla treningu: batch 5481 - 5544\n","Generuję dane adwersarialne dla treningu: batch 5544 - 5607\n","Generuję dane adwersarialne dla treningu: batch 5607 - 5670\n","Generuję dane adwersarialne dla treningu: batch 5670 - 5733\n","Generuję dane adwersarialne dla treningu: batch 5733 - 5796\n","Generuję dane adwersarialne dla treningu: batch 5796 - 5859\n","Generuję dane adwersarialne dla treningu: batch 5859 - 5922\n","Generuję dane adwersarialne dla treningu: batch 5922 - 5985\n","Generuję dane adwersarialne dla treningu: batch 5985 - 6048\n","Generuję dane adwersarialne dla treningu: batch 6048 - 6111\n","Generuję dane adwersarialne dla treningu: batch 6111 - 6174\n","Generuję dane adwersarialne dla treningu: batch 6174 - 6237\n","Generuję dane adwersarialne dla treningu: batch 6237 - 6300\n","Generuję dane adwersarialne dla treningu: batch 6300 - 6363\n","Generuję dane adwersarialne dla treningu: batch 6363 - 6426\n","Generuję dane adwersarialne dla treningu: batch 6426 - 6489\n","Generuję dane adwersarialne dla treningu: batch 6489 - 6552\n","Generuję dane adwersarialne dla treningu: batch 6552 - 6615\n","Generuję dane adwersarialne dla treningu: batch 6615 - 6678\n","Generuję dane adwersarialne dla treningu: batch 6678 - 6741\n","Generuję dane adwersarialne dla treningu: batch 6741 - 6804\n","Generuję dane adwersarialne dla treningu: batch 6804 - 6867\n","Generuję dane adwersarialne dla treningu: batch 6867 - 6930\n","Generuję dane adwersarialne dla treningu: batch 6930 - 6993\n","Generuję dane adwersarialne dla treningu: batch 6993 - 7056\n","Generuję dane adwersarialne dla treningu: batch 7056 - 7119\n","Generuję dane adwersarialne dla treningu: batch 7119 - 7182\n","Generuję dane adwersarialne dla treningu: batch 7182 - 7245\n","Generuję dane adwersarialne dla treningu: batch 7245 - 7308\n","Generuję dane adwersarialne dla treningu: batch 7308 - 7371\n","Generuję dane adwersarialne dla treningu: batch 7371 - 7434\n","Generuję dane adwersarialne dla treningu: batch 7434 - 7497\n","Generuję dane adwersarialne dla treningu: batch 7497 - 7560\n","Generuję dane adwersarialne dla treningu: batch 7560 - 7623\n","Generuję dane adwersarialne dla treningu: batch 7623 - 7686\n","Generuję dane adwersarialne dla treningu: batch 7686 - 7749\n","Generuję dane adwersarialne dla treningu: batch 7749 - 7812\n","Generuję dane adwersarialne dla treningu: batch 7812 - 7875\n","Generuję dane adwersarialne dla treningu: batch 7875 - 7938\n","Generuję dane adwersarialne dla treningu: batch 7938 - 8001\n","Generuję dane adwersarialne dla treningu: batch 8001 - 8064\n","Generuję dane adwersarialne dla treningu: batch 8064 - 8127\n","Generuję dane adwersarialne dla treningu: batch 8127 - 8190\n","Generuję dane adwersarialne dla treningu: batch 8190 - 8253\n","Generuję dane adwersarialne dla treningu: batch 8253 - 8316\n","Generuję dane adwersarialne dla treningu: batch 8316 - 8379\n","Generuję dane adwersarialne dla treningu: batch 8379 - 8442\n","Generuję dane adwersarialne dla treningu: batch 8442 - 8505\n","Generuję dane adwersarialne dla treningu: batch 8505 - 8568\n","Generuję dane adwersarialne dla treningu: batch 8568 - 8631\n","Generuję dane adwersarialne dla treningu: batch 8631 - 8694\n","Generuję dane adwersarialne dla treningu: batch 8694 - 8757\n","Generuję dane adwersarialne dla treningu: batch 8757 - 8820\n","Generuję dane adwersarialne dla treningu: batch 8820 - 8883\n","Generuję dane adwersarialne dla treningu: batch 8883 - 8946\n","Generuję dane adwersarialne dla treningu: batch 8946 - 9009\n","Generuję dane adwersarialne dla treningu: batch 9009 - 9072\n","Generuję dane adwersarialne dla treningu: batch 9072 - 9135\n","Generuję dane adwersarialne dla treningu: batch 9135 - 9198\n","Generuję dane adwersarialne dla treningu: batch 9198 - 9261\n","Generuję dane adwersarialne dla treningu: batch 9261 - 9324\n","Generuję dane adwersarialne dla treningu: batch 9324 - 9387\n","Generuję dane adwersarialne dla treningu: batch 9387 - 9450\n","Generuję dane adwersarialne dla treningu: batch 9450 - 9513\n","Generuję dane adwersarialne dla treningu: batch 9513 - 9576\n","Generuję dane adwersarialne dla treningu: batch 9576 - 9639\n","Generuję dane adwersarialne dla treningu: batch 9639 - 9702\n","Generuję dane adwersarialne dla treningu: batch 9702 - 9765\n","Generuję dane adwersarialne dla treningu: batch 9765 - 9828\n","Generuję dane adwersarialne dla treningu: batch 9828 - 9891\n","Generuję dane adwersarialne dla treningu: batch 9891 - 9954\n","Generuję dane adwersarialne dla treningu: batch 9954 - 10017\n","Generuję dane adwersarialne dla treningu: batch 10017 - 10080\n","Generuję dane adwersarialne dla treningu: batch 10080 - 10143\n","Generuję dane adwersarialne dla treningu: batch 10143 - 10206\n","Generuję dane adwersarialne dla treningu: batch 10206 - 10269\n","Generuję dane adwersarialne dla treningu: batch 10269 - 10332\n","Generuję dane adwersarialne dla treningu: batch 10332 - 10395\n","Generuję dane adwersarialne dla treningu: batch 10395 - 10458\n","Generuję dane adwersarialne dla treningu: batch 10458 - 10521\n","Generuję dane adwersarialne dla treningu: batch 10521 - 10584\n","Generuję dane adwersarialne dla treningu: batch 10584 - 10647\n","Generuję dane adwersarialne dla treningu: batch 10647 - 10710\n","Generuję dane adwersarialne dla treningu: batch 10710 - 10773\n","Generuję dane adwersarialne dla treningu: batch 10773 - 10836\n","Generuję dane adwersarialne dla treningu: batch 10836 - 10899\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-1fbdd1e16f6c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Generuję dane adwersarialne dla treningu: batch {i} - {i+batch_size_train}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0madv_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpgd_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mx_train_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-f50434e47103>\u001b[0m in \u001b[0;36mpgd_attack\u001b[0;34m(model, images, labels, epsilon, c, num_iterations, norm_type, threshold)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;31m# 7. Call the layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m                 \u001b[0mcurrent_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_autocast_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0mnew_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0mname_scope_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pop_on_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_name_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5772\u001b[0m     \"\"\"\n\u001b[1;32m   5773\u001b[0m     \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5774\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5775\u001b[0m       \u001b[0;31m# Names are not auto-incremented in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5776\u001b[0m       \u001b[0;31m# A trailing slash breaks out of nested name scopes, indicating a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecuting_eagerly\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_switches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m     \u001b[0;34m\"\"\"Returns True if current thread has eager executing enabled.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Generowanie danych adwersarialnych dla zbioru testowego\n","batch_size_test = 42\n","x_test_adv = []\n","for i in range(0, len(x_test), batch_size_test):\n","    batch_images = x_test[i:i+batch_size_test]\n","    batch_labels = y_test[i:i+batch_size_test]\n","    print(f\"Generuję dane adwersarialne dla testów: batch {i} - {i+batch_size_test}\")\n","    adv_images = pgd_attack(model, batch_images, batch_labels, epsilon=0.01, c=0.3, num_iterations=50, norm_type=\"L2\")\n","    x_test_adv.append(adv_images)\n","\n","x_test_adv = np.concatenate(x_test_adv, axis=0)\n","\n","# Zapis danych adwersarialnych dla zbioru testowego\n","np.savez_compressed(\"adversarial_test_images.npz\", X_test_adv=x_test_adv)\n","print(\"Dane adwersarialne dla testów zostały zapisane jako 'adversarial_test_images.npz'.\")\n"],"metadata":{"id":"QYebS2tMYUuz","executionInfo":{"status":"aborted","timestamp":1738489074997,"user_tz":-60,"elapsed":4,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}},"collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Wczytanie wygenerowanych danych"],"metadata":{"id":"DBOWu_x88fkc"}},{"source":["# Wczytywanie danych z plików\n","data_train = np.load(\"adversarial_train_images.npz\")\n","x_train_adv = data_train[\"X_train_adv\"]\n","print(f\"Wczytano dane adwersarialne dla treningu: {x_train_adv.shape}\")\n","\n","data_test = np.load(\"adversarial_test_images.npz\")\n","x_test_adv = data_test[\"X_test_adv\"]\n","print(f\"Wczytano dane adwersarialne dla testów: {x_test_adv.shape}\")"],"cell_type":"code","metadata":{"id":"36iyiUFYUej4","executionInfo":{"status":"aborted","timestamp":1738489074998,"user_tz":-60,"elapsed":5,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Model, Sequential, load_model\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n","from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import tensorflow as tf\n","\n","# Funkcja do stworzenia modelu pomocniczego\n","def create_auxiliary_model():\n","    model = Sequential()\n","    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same',\n","                     data_format='channels_last', input_shape=(28, 28, 1)))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='relu', data_format='channels_last'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='valid', strides=2))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.25))\n","    model.add(Dense(1024, activation='relu'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.5))\n","\n","    # Dostosowanie warstwy wyjściowej do klasyfikacji binarnej\n","    model.add(Dense(1, activation='sigmoid'))  # 1 neuron wyjściowy dla klasyfikacji binarnej\n","\n","    return model\n","\n","# Wczytanie lub stworzenie istniejącego modelu bazowego\n","try:\n","    base_model = load_model(\"model.h5\")  # Zakładamy, że model istnieje\n","except OSError:\n","    base_model = Sequential([\n","        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","        MaxPooling2D((2, 2)),\n","        Flatten(),\n","        Dense(128, activation='relu'),\n","        Dense(10, activation='softmax')\n","    ])\n","    base_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Zamrożenie warstw istniejącego modelu\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Tworzenie modelu pomocniczego na podstawie istniejącego\n","aux_model_extended = Sequential(base_model.layers[:-1])  # Wszystkie warstwy oprócz wyjściowej\n","aux_model_extended.add(Dense(512, activation='relu'))\n","aux_model_extended.add(BatchNormalization())\n","aux_model_extended.add(Dropout(0.25))\n","aux_model_extended.add(Dense(1024, activation='relu'))\n","aux_model_extended.add(BatchNormalization())\n","aux_model_extended.add(Dropout(0.5))\n","aux_model_extended.add(Dense(1, activation='sigmoid'))  # Wyjście binarne\n","\n","# Kompilacja modelu pomocniczego\n","aux_model_extended.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"KVMAmpCe-KdI","executionInfo":{"status":"aborted","timestamp":1738489074998,"user_tz":-60,"elapsed":4,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model pomocniczy na podstawie modelu głównego"],"metadata":{"id":"1s1p6wOC7uOK"}},{"cell_type":"code","source":["from sklearn.utils import shuffle\n","\n","# Lista proporcji split\n","splits = [0.2, 0.4, 0.5, 0.3]\n","\n","for split in splits:\n","    num_adv_samples_train = int(len(x_train_adv) * split)\n","\n","    # Łączenie danych oryginalnych i adwersarialnych dla treningu\n","    x_train_combined = np.concatenate([x_train, x_train_adv[:num_adv_samples_train]], axis=0)\n","    y_train_combined = np.concatenate([np.zeros(len(x_train)), np.ones(num_adv_samples_train)], axis=0)  # 0: prawdziwe, 1: adwersarialne\n","    print(f\"Wczytano dane adwersarialne dla treningu: {x_train_combined.shape}\")\n","    print(f\"Wczytano dane adwersarialne dla treningu: {y_train_combined.shape}\")\n","\n","    num_adv_samples_test = int(len(x_test_adv) * split)\n","\n","    # Łączenie danych oryginalnych i adwersarialnych dla testów\n","    x_test_combined = np.concatenate([x_test, x_test_adv[:num_adv_samples_test]], axis=0)\n","    y_test_combined = np.concatenate([np.zeros(len(x_test)), np.ones(len(x_test_adv[:num_adv_samples_test]))], axis=0)  # 0: prawdziwe, 1: adwersarialne\n","    print(f\"Wczytano dane adwersarialne dla testu: {x_test_combined.shape}\")\n","    print(f\"Wczytano dane adwersarialne dla testu: {y_test_combined.shape}\")\n","\n","    # Mieszanie danych\n","    x_train_combined, y_train_combined = shuffle(x_train_combined, y_train_combined, random_state=42)\n","\n","\n","    # Generator danych z augmentacją\n","    datagen = ImageDataGenerator(\n","        rotation_range=10,\n","        width_shift_range=0.1,\n","        height_shift_range=0.1,\n","        zoom_range=0.1\n","    )\n","    datagen.fit(x_train_combined)\n","\n","    # Learning Rate Scheduler\n","    reduce_lr = LearningRateScheduler(lambda epoch: 1e-3 * 0.9 ** epoch)\n","\n","    # Early Stopping\n","    early_stopping = EarlyStopping(\n","        min_delta=0.001,\n","        patience=20,\n","        restore_best_weights=True\n","    )\n","\n","    # Trening modelu pomocniczego\n","    print(f\"Trening modelu dla split: {split}\")\n","    history = aux_model_extended.fit(\n","        datagen.flow(x_train_combined, y_train_combined, batch_size=64),\n","        epochs=50,\n","        validation_data=(x_test_combined, y_test_combined),\n","        verbose=1,\n","        steps_per_epoch=x_train_combined.shape[0] // 64,\n","        callbacks=[reduce_lr, early_stopping]\n","    )\n","\n","    # Zapis modelu\n","    model_name = f\"ADM_model_extended_split_{split}.h5\"\n","    aux_model_extended.save(model_name)\n","    print(f\"Modele zostały zapisane: {model_name}\")\n","\n"],"metadata":{"id":"WEaRUINF77lQ","executionInfo":{"status":"aborted","timestamp":1738489074998,"user_tz":-60,"elapsed":4,"user":{"displayName":"Escooobar","userId":"12228491276356832373"}}},"execution_count":null,"outputs":[]}]}